{"id":"e0","type":"say","title":"Welcome","narration":"Welcome to the Debrief codebase. This walkthrough covers the core architecture so you can start contributing quickly. We'll follow the data from extension activation through to audio playback."}
{"id":"s1","type":"sectionStart","title":"Extension Entry Point","narration":""}
{"id":"e1","type":"highlightRange","filePath":"src/extension.ts","range":{"startLine":1,"startCol":0,"endLine":16,"endCol":0},"title":"Imports","narration":"Everything starts here. These imports map directly to the major subsystems: replay engine, TTS audio, timeline UI, file watcher, and the HTTP server for agent integration."}
{"id":"e2","type":"highlightRange","filePath":"src/extension.ts","range":{"startLine":18,"startCol":0,"endLine":20,"endCol":0},"title":"Activate function","narration":"The activate function is where VS Code hands us control. First thing we do is create an output channel for logging."}
{"id":"e3","type":"highlightRange","filePath":"src/extension.ts","range":{"startLine":51,"startCol":0,"endLine":62,"endCol":0},"title":"Handler context","narration":"This is the handler context, a shared bag of services that gets passed to every event handler. It holds the decoration manager, TTS player, follow mode controller, and more. Think of it as our dependency injection container."}
{"id":"e4","type":"highlightRange","filePath":"src/extension.ts","range":{"startLine":64,"startCol":0,"endLine":67,"endCol":0},"title":"Engine creation","narration":"The replay engine is created with that context. Notice line 66, we patch the engine reference back into the context because there's a circular dependency. Handlers need the engine, but the engine creates the handlers."}
{"id":"e5","type":"highlightRange","filePath":"src/extension.ts","range":{"startLine":139,"startCol":0,"endLine":149,"endCol":0},"title":"Timeline sidebar","narration":"The timeline sidebar is a WebviewViewProvider registered under the ID debrief.timeline. This is what renders the step list, progress bar, and playback controls in the sidebar panel."}
{"id":"s1e","type":"sectionEnd","title":"","narration":""}
{"id":"s2","type":"sectionStart","title":"Agent Integration","narration":""}
{"id":"e6","type":"highlightRange","filePath":"src/extension.ts","range":{"startLine":151,"startCol":0,"endLine":154,"endCol":0},"title":"File watcher setup","narration":"The file watcher monitors the .debrief/replay directory for new JSONL trace files. It's how the extension detects when an AI agent finishes writing a walkthrough."}
{"id":"e7","type":"highlightRange","filePath":"src/agent/fileWatcher.ts","range":{"startLine":38,"startCol":0,"endLine":44,"endCol":0},"title":"Glob pattern","narration":"Here's the watcher itself. The glob pattern matches any JSONL file inside .debrief/replay, including subdirectories. It listens for both file creation and modification events."}
{"id":"e8","type":"highlightRange","filePath":"src/agent/fileWatcher.ts","range":{"startLine":56,"startCol":0,"endLine":77,"endCol":0},"title":"Per-file debounce","narration":"When an agent writes a trace file incrementally, we debounce per file URI. Each file gets its own 500 millisecond timer, so simultaneous writes to different files don't interfere with each other."}
{"id":"e9","type":"highlightRange","filePath":"src/extension.ts","range":{"startLine":223,"startCol":0,"endLine":235,"endCol":0},"title":"HTTP server","narration":"The other integration path is this HTTP server. AI agents can stream events to it in real-time on port 53931. It auto-starts by default, making the extension immediately available to any local agent."}
{"id":"s2e","type":"sectionEnd","title":"","narration":""}
{"id":"s3","type":"sectionStart","title":"Replay Engine","narration":""}
{"id":"e10","type":"highlightRange","filePath":"src/replay/engine.ts","range":{"startLine":18,"startCol":0,"endLine":22,"endCol":0},"title":"Engine state","narration":"The replay engine is a state machine. Its core state is simple: an array of trace events, a current index, and a handler context. Everything else builds on these three."}
{"id":"e11","type":"highlightRange","filePath":"src/replay/engine.ts","range":{"startLine":24,"startCol":0,"endLine":28,"endCol":0},"title":"Playback state","narration":"Playback adds a few more fields. The play state tracks stopped, playing, or paused. The advance timer handles auto-advance timing, and the TTS completion disposable links audio completion to step progression."}
{"id":"e12","type":"highlightRange","filePath":"src/replay/engine.ts","range":{"startLine":33,"startCol":0,"endLine":34,"endCol":0},"title":"Navigation epoch","narration":"The navigation epoch is a counter that increments on every goToStep call. It's how we detect and discard stale handler executions when the user clicks rapidly through steps."}
{"id":"e13","type":"highlightRange","filePath":"src/replay/engine.ts","range":{"startLine":122,"startCol":0,"endLine":134,"endCol":0},"title":"Load method","narration":"When a trace is loaded, we reset everything, store the events, and kick off TTS pre-generation in the background. The preloader starts generating audio for all steps so they're cached before the user gets there."}
{"id":"e14","type":"highlightRange","filePath":"src/replay/engine.ts","range":{"startLine":181,"startCol":0,"endLine":192,"endCol":0},"title":"goToStep: cleanup","narration":"goToStep is the heart of navigation. The first thing it does is clean up: increment the epoch, cancel any pending advance timer, dispose the TTS completion listener, and stop any playing audio. This prevents overlapping voices."}
{"id":"e15","type":"highlightRange","filePath":"src/replay/engine.ts","range":{"startLine":209,"startCol":0,"endLine":221,"endCol":0},"title":"goToStep: handler execution","narration":"Then it locks TTS to the current event ID and executes the appropriate handler. The skipTts flag is set temporarily on the context so handlers know whether to start narration."}
{"id":"e16","type":"highlightRange","filePath":"src/replay/engine.ts","range":{"startLine":236,"startCol":0,"endLine":253,"endCol":0},"title":"goToStep: stale check","narration":"After the handler finishes, we check if the epoch still matches. If the user clicked another step while the handler was doing async work like opening files, we bail out. Otherwise, we notify the UI and, if playing, schedule the next auto-advance."}
{"id":"s3e","type":"sectionEnd","title":"","narration":""}
{"id":"s4","type":"sectionStart","title":"Playback and Auto-Advance","narration":""}
{"id":"e17","type":"highlightRange","filePath":"src/replay/engine.ts","range":{"startLine":284,"startCol":0,"endLine":298,"endCol":0},"title":"Play method","narration":"The play method sets the state to playing and either starts from step zero if nothing is selected, or re-executes the current step's handler to kick off TTS. goToStep handles the rest since it sees the playing state."}
{"id":"e18","type":"highlightRange","filePath":"src/replay/engine.ts","range":{"startLine":331,"startCol":0,"endLine":339,"endCol":0},"title":"Pause method","narration":"Pause is the inverse. It clears all timers and listeners, stops TTS audio immediately, and fires the state change event. Clean and immediate."}
{"id":"e19","type":"highlightRange","filePath":"src/replay/engine.ts","range":{"startLine":355,"startCol":0,"endLine":395,"endCol":0},"title":"TTS sync and auto-advance","narration":"This is the synchronization mechanism. When a step has narration, we record the TTS request ID and listen for playback completion. Only when the audio finishes and the request ID matches do we schedule the next advance. There's also a 60-second safety timeout in case TTS hangs."}
{"id":"s4e","type":"sectionEnd","title":"","narration":""}
{"id":"s5","type":"sectionStart","title":"Event Handlers","narration":""}
{"id":"e20","type":"highlightRange","filePath":"src/replay/handlers/highlightRange.ts","range":{"startLine":7,"startCol":0,"endLine":17,"endCol":0},"title":"Handler: highlightRange","narration":"This is the most common handler. It first parses any line reference tags from the narration text. These let trace authors specify which lines to highlight at specific moments during speech."}
{"id":"e21","type":"highlightRange","filePath":"src/replay/handlers/highlightRange.ts","range":{"startLine":19,"startCol":0,"endLine":23,"endCol":0},"title":"TTS-first pattern","narration":"Notice the TTS-first pattern here. We start audio playback before doing any file navigation. This means the user hears the explanation as the code appears, just like a human presenter would do it."}
{"id":"e22","type":"highlightRange","filePath":"src/replay/handlers/highlightRange.ts","range":{"startLine":62,"startCol":0,"endLine":78,"endCol":0},"title":"File navigation","narration":"Then we open the file and show it in the editor. The handler checks if we're switching files and shows a brief transition indicator. After opening, it applies decorations and reveals the highlighted range."}
{"id":"s5e","type":"sectionEnd","title":"","narration":""}
{"id":"s6","type":"sectionStart","title":"TTS Audio System","narration":""}
{"id":"e23","type":"highlightRange","filePath":"src/audio/ttsPlayer.ts","range":{"startLine":14,"startCol":0,"endLine":28,"endCol":0},"title":"TTS player state","narration":"The TTS player manages audio generation and playback. Key state: an audio cache so we never regenerate the same narration, a request ID for cancellation tracking, and an allowed event ID that prevents stale handlers from starting the wrong audio."}
{"id":"e24","type":"highlightRange","filePath":"src/audio/ttsPlayer.ts","range":{"startLine":98,"startCol":0,"endLine":120,"endCol":0},"title":"speakAsync method","narration":"speakAsync is the main entry point. It first checks the allowed event ID guard, then stops any current audio, increments the request ID, and fires off generation and playback. The stop-then-increment order is important for correct completion event handling."}
{"id":"e25","type":"highlightRange","filePath":"src/audio/ttsPlayer.ts","range":{"startLine":261,"startCol":0,"endLine":279,"endCol":0},"title":"Stop method","narration":"Stop kills the audio process, sets isPlaying to false, and fires a completion event with cancelled set to true. The engine's TTS listener checks this flag to know whether to auto-advance or not."}
{"id":"e26","type":"highlightRange","filePath":"src/audio/ttsPlayer.ts","range":{"startLine":389,"startCol":0,"endLine":408,"endCol":0},"title":"Platform audio players","narration":"Audio playback is platform-specific. Windows uses PowerShell with WPF's MediaPlayer, macOS uses afplay, and Linux uses mpv. Each spawns a child process that we can kill to stop playback instantly."}
{"id":"e27","type":"highlightRange","filePath":"src/audio/ttsPlayer.ts","range":{"startLine":434,"startCol":0,"endLine":442,"endCol":0},"title":"Process lifecycle guard","narration":"This guard is critical. When we kill a process and immediately spawn a new one, the killed process's close event fires asynchronously and would corrupt the new process's state. By checking if the process reference still matches, we prevent that race condition."}
{"id":"s6e","type":"sectionEnd","title":"","narration":""}
{"id":"s7","type":"sectionStart","title":"Timeline UI","narration":""}
{"id":"e28","type":"highlightRange","filePath":"src/ui/timelineView.ts","range":{"startLine":21,"startCol":0,"endLine":26,"endCol":0},"title":"TimelineViewProvider","narration":"The timeline sidebar is a WebviewViewProvider. It holds a reference to the webview and the engine, and acts as the bridge between them."}
{"id":"e29","type":"highlightRange","filePath":"src/ui/timelineView.ts","range":{"startLine":40,"startCol":0,"endLine":45,"endCol":0},"title":"Engine event wiring","narration":"In the constructor, we subscribe to every engine event and push state updates to the webview. Step changes, session loads, play state changes, all of them trigger an update."}
{"id":"e30","type":"highlightRange","filePath":"src/ui/timelineView.ts","range":{"startLine":86,"startCol":0,"endLine":100,"endCol":0},"title":"Ready handshake","narration":"The webview communicates back via messages. The ready handshake is important: when the webview's JavaScript loads, it posts a ready message. Only then do we push the current session state. This replaces an old timing hack and prevents a race where state was sent before the webview could receive it."}
{"id":"s7e","type":"sectionEnd","title":"","narration":""}
{"id":"e31","type":"say","title":"Next Steps","narration":"That's the core architecture. The data flows from trace files through the engine, into handlers that open files and start audio, with the timeline keeping everything in sync. For your first contribution, check the issues list or try adding a new handler type. Good luck!"}
